{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# TextBlob: An Introduction of Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## What is NLP?\n",
    "\n",
    "* Computer understanding and manipulation of human language\n",
    "* A way for computers to analyze, understand, and derive meaning from human language in a smart and useful way\n",
    "* Intersection of computer science, artificial intelligence, and computational linguistics\n",
    "\n",
    "NLP algorithms are typically based on machine learning algorithms. Instead of hand-coding large sets of rules, NLP can rely on machine learning to automatically learn these rules by analyzing a set of examples (i.e. a large corpus, like a book, down to a collection of sentences), and making a statical inference. In general, the more data analyzed, the more accurate the model will be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Two Subfields of NLP\n",
    "\n",
    "There are two common subfields of natural language processing:\n",
    "\n",
    "* Natural Language Understanding (NLU)\n",
    "    - A process used to convert human language into data with a form that encapsulates meaning and context in a computer-interpretable form.\n",
    "    - This is a work in progress in data science\n",
    "    - Understanding human language is difficult\n",
    "* Natural Language Generation (NLG)\n",
    "    - Uses NLU to generate human language that appears natural and relevant.\n",
    "    - Chat bots and software that automatically generates textual content use NLG.\n",
    "    \n",
    "These subfields do not completely makeup with space of NLP:\n",
    "\n",
    "* NLU includes things like\n",
    "    - relationship extraction\n",
    "    - sentiment analysis\n",
    "    - summarization\n",
    "    - *semantic* parsing\n",
    "* NLP also includes (not part of NLU)\n",
    "    - *syntactic* parsing\n",
    "    - text categorization\n",
    "    - part of speech tagging\n",
    "    \n",
    "While some parts of NLP (e.g. POS tagging) are used in NLU, they are not strictly components of NLU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Challenges in NLP\n",
    "\n",
    "NLP has many challenges, and the field is not yet mature. Some of the challenges currently faced are\n",
    "\n",
    "* Ambiguity of language\n",
    "    - syntactic ambiguity: some sentences can have multiple interpretations\n",
    "    - words with multiple definitions (e.g. patient: to tolerate delays? a hospital patient?)\n",
    "* Context affects meaning\n",
    "    - social context\n",
    "    - time of day\n",
    "    - content of previous sentences\n",
    "* Other\n",
    "    - sarcasm, humor, slang, etc.\n",
    "    \n",
    "Most or all of these are tied to NLU in one way or another. Further advancements in AI are needed to create general solutions that can handle the many form of language encountered. For example, the form of language encountered in a novel is very different from what you would find in a social media feed (e.g. Tweets)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Some Uses for NLP\n",
    "\n",
    "The uses for NLP grow as new and creative ideas arise, but some common uses are\n",
    "\n",
    "* automatic summarization\n",
    "* translation\n",
    "* named entity recognition\n",
    "    - person\n",
    "    - place\n",
    "    - organization\n",
    "    - object\n",
    "    - etc.\n",
    "* relationship extraction\n",
    "* sentiment analysis\n",
    "* speech recognition\n",
    "* topic segmentation / text classification\n",
    "* grammar correction\n",
    "* chat bots\n",
    "* automatic tag, keyword, and content generation\n",
    "\n",
    "Speech recognition is one use that doesn't *require* NLU, but it can be made better with it. It doesn't require it because a machine can recognize various words and phrases, and then take certain actions without actually understanding anything about what was said.\n",
    "\n",
    "**Some specific use cases for NLP:**\n",
    "\n",
    "* Analyze social media and forums to gain insight into what customers are saying\n",
    "    - identify new product opportunities,\n",
    "    - problems with current products/services,\n",
    "    - overall user/customer sentiment\n",
    "* Spam detection\n",
    "* Financial algorithmic trading\n",
    "    - extract info from news that impacts trading decisions\n",
    "* Answering questions (e.g. chat bots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Techniques &amp; Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Techniques\n",
    "\n",
    "* **Tokenization**: split text into sentences, words, and noun-phrases\n",
    "* **Tagging**: String -> tagged list of pairs `('word', 'POS')`\n",
    "\n",
    "    Ex: `'This is a string'` -> `[('This', 'DT'), ('is', 'VBZ'), ('a', 'DT'), ('string', 'NN')]`\n",
    "  \n",
    "  \n",
    "* **Parsing** (syntactic structure): String -> hierarchical structure with syntax tags\n",
    "\n",
    "    Ex: `'This is a string'` -> `'This/DT/O/O is/VBZ/B-VP/O a/DT/B-NP/O string/NN/I-NP/O'`\n",
    "\n",
    "* **Information Extraction**: \n",
    "    - named entity extraction: string in -> output text with labeled entities (person, company, location, etc.)\n",
    "    - relationships between entities: string in -> output entity relationships\n",
    "* **n-grams**:\n",
    "    - string in -> output list of n-tuples of successive words\n",
    "    - n-grams are used as features in machine learning\n",
    "    \n",
    "    Ex (2-gram): `'This is a string'` -> `(['This', 'is'], ['is', 'a'], ['a', 'string'])`\n",
    "    \n",
    "*These will be discussed in more detail as they come up.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Tools\n",
    "\n",
    "There are many tools availble for NLP. Some popular choices are\n",
    "\n",
    "* Stanford's Core NLP Suite\n",
    "* Natural Language Toolkit (NLTK)\n",
    "* Apache OpenNLP\n",
    "* WordNet\n",
    "* **TextBlob**\n",
    "\n",
    "We will be working with TextBlob, which builds off of (and can integrate with) NLTK and WordNet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# TextBlob: An Introduction of Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Installation\n",
    "\n",
    "To install TextBlob, open a new Terminal and enter the following:\n",
    "\n",
    "```\n",
    "$ pip install -U textblob\n",
    "$ python -m textblob.download_corpora\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Getting Started\n",
    "\n",
    "From here on, you can follow along with the notebook and create new notes and try out code as you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# import what we need\n",
    "import pandas as pd\n",
    "from pandas import DataFrame as DF, Series\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# read data\n",
    "\n",
    "# use only the column called 'text'\n",
    "data = pd.read_csv('tweets.csv', usecols=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0                @VirginAmerica What @dhepburn said.\n",
       "1  @VirginAmerica plus you've added commercials t...\n",
       "2  @VirginAmerica I didn't today... Must mean I n..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Create a TextBlob object\n",
    "\n",
    "`TextBlob` objects are the foundation of everything we will be doing. They take a string as an input and create an object on which we can apply many of the TextBlob methods.\n",
    "\n",
    "Let's create a blob using a tweet in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create a blob from the tweet at index 25\n",
    "tweet = data.text[25]\n",
    "blob = TextBlob(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# TextBlob Methods: Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Tokenization allows us to split a string (a paragraph, a page, etc.) into various \"tokens\" that become useful in further processing and analysis. Tokenization also occurs on the back-end of some methods.\n",
    "\n",
    "Let's look at some tokenization options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Sentences\n",
    "\n",
    "Using the `sentences` method we get a list of `Sentence` objects, each containing (in order) all of the sentences that make up the string passed to `TextBlob`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"@VirginAmerica status match program.\"),\n",
       " Sentence(\"I applied and it's been three weeks.\"),\n",
       " Sentence(\"Called and emailed with no response.\")]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return list of Sentence objects\n",
    "blob.sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Similar to `TextBlob` objects, we can use various methods with `Sentence` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Called', 'VBN'),\n",
       " ('and', 'CC'),\n",
       " ('emailed', 'VBN'),\n",
       " ('with', 'IN'),\n",
       " ('no', 'DT'),\n",
       " ('response', 'NN')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the first sentence\n",
    "s = blob.sentences[2]\n",
    "# get tags from this sentence\n",
    "s.tags[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Words\n",
    "\n",
    "Instead of a list of sentences, we can get a `WordList` object that returns all of the individual words in our string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['VirginAmerica', 'status', 'match', 'program', 'I', 'applied', 'and', 'it', \"'s\", 'been', 'three', 'weeks', 'Called', 'and', 'emailed', 'with', 'no', 'response'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return WordList object (works like a standard list in Python)\n",
    "blob.words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can access words in a `WordList` just like a regular Python list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['it', \"'s\"])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.words[7:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Notice**: TextBlob doesn't do the best job of handling contractions and possessive forms. Ex: \"it's\" is split into \"it\" and \"'s\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Word Counts\n",
    "\n",
    "We can get a dict that contains all the unique words in our string as keys, and counts for each as values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'and': 2,\n",
       "             'applied': 1,\n",
       "             'been': 1,\n",
       "             'called': 1,\n",
       "             'emailed': 1,\n",
       "             'i': 1,\n",
       "             'it': 1,\n",
       "             'match': 1,\n",
       "             'no': 1,\n",
       "             'program': 1,\n",
       "             'response': 1,\n",
       "             's': 1,\n",
       "             'status': 1,\n",
       "             'three': 1,\n",
       "             'virginamerica': 1,\n",
       "             'weeks': 1,\n",
       "             'with': 1})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns defaultdict with unique words as keys and counts as values.\n",
    "blob.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# we can get counts for individual words is two ways\n",
    "# 1. use the count method on a WordList\n",
    "print(blob.words.count('and'))\n",
    "# 2. access a key in the word_counts dict\n",
    "print(blob.word_counts['and'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**NOTE!**\n",
    "\n",
    "if you use `word_counts['some_word']` and that word is not originally in the defaultdict, it will be added with a count of zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'a': 1, 'of': 1, 'string': 1, 'words': 1})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of above\n",
    "b = TextBlob('a string of words')\n",
    "b.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get count of word not in dict\n",
    "b.word_counts['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'a': 1, 'of': 1, 'string': 1, 'test': 0, 'words': 1})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at contents of dict again\n",
    "# notice that 'test' is now included\n",
    "b.word_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Noun Phrases\n",
    "\n",
    "**Noun phrases:** a word or group of words that functions in a sentence as subject, object, or prepositional object.\n",
    "\n",
    "Examples of __noun phrases__ are underlined in the sentences below. The **head** noun appears in bold.\n",
    "\n",
    "* __The election-year **politics**__ are annoying for __many **people**__.\n",
    "* __Almost every **sentence**__ contains __at least one noun **phrase**__.\n",
    "* __Current economic **weakness**__ may be __a **result** of high energy prices__.\n",
    "\n",
    "Noun phrases can be identified by the possibility of pronoun substitution, as is illustrated in the examples below.\n",
    "\n",
    "a. __This **sentence**__ contains __two noun **phrases**__.<br>\n",
    "b. **It** contains **them**.\n",
    "\n",
    "We can get a `WordList` containing noun phrases using the `noun_phrase` method on a blob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"@VirginAmerica status match program.\"),\n",
       " Sentence(\"I applied and it's been three weeks.\"),\n",
       " Sentence(\"Called and emailed with no response.\")]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['virginamerica', 'pretty graphics', 'minimal iconography'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return WordList with noun phrases for tweet at index 11\n",
    "TextBlob(data.text[11]).noun_phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The algorithm used isn't perfect, but things rarely are in NLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice Problems\n",
    "\n",
    "1. Create a TextBlob object called blob using tweet at index 41\n",
    "2. Print each sentence in blob on a separate line\n",
    "3. Get word counts in descending order (most frequent first)\n",
    "4. Come up with two ways to get the total word count for blob\n",
    "5. Get all noun-phrases in blob. What is wrong with the second “phrase” in the results?\n",
    "6. Select all entries in the data that contain more than 3 noun phrases\n",
    "7. **Extra:** Using a similar method as in 6, print one tweet that has exactly 3 sentences without creating a list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# TextBlob Methods: POS & Morphology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Here we will cover all of the following:\n",
    "    \n",
    "* **part-of-speech (POS) tagging**: get list of tuples containing each word and it’s part of speech (e.g. noun)\n",
    "* **pluralization**: get the plural form of any singular words\n",
    "* **singularization**: get the singular form of any plural words\n",
    "* **lemmatization**: get the stripped/unmodified version of a word (e.g. singing -> sing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## part-of-speech (POS) tagging\n",
    "\n",
    "Using the `tags` method, we can get a list of doubles that contains every word in our string paired with its part of speech, as determined by the algorithm.\n",
    "\n",
    "POS tagging (also grammatical tagging) is useful for understanding context and grammar. Many words can belong to different parts of speech, depending on the context and words around them. POS tagging attempts to disambiguate a text by determining most likely parts of speech for each word based on the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('@', 'NN'),\n",
       " ('VirginAmerica', 'NNP'),\n",
       " ('status', 'NN'),\n",
       " ('match', 'NN'),\n",
       " ('program', 'NN'),\n",
       " ('I', 'PRP'),\n",
       " ('applied', 'VBD'),\n",
       " ('and', 'CC'),\n",
       " ('it', 'PRP'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('been', 'VBN'),\n",
       " ('three', 'CD'),\n",
       " ('weeks', 'NNS'),\n",
       " ('Called', 'VBN'),\n",
       " ('and', 'CC'),\n",
       " ('emailed', 'VBN'),\n",
       " ('with', 'IN'),\n",
       " ('no', 'DT'),\n",
       " ('response', 'NN')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return list of tuples containing words in a string and the part of speech that each belongs to\n",
    "blob.tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The tags each have a unique meaning. For example:\n",
    "* 'VBX': verb (X indicates type of verb)\n",
    "* 'DT': determiner\n",
    "\n",
    "A comprehensive table can be found at http://www.clips.ua.ac.be/pages/mbsp-tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## pluralization\n",
    "\n",
    "This is a relatively simple rule-based process that takes the singular form of a word and applies the correct pluralization to it.\n",
    "\n",
    "In TextBlob we can pluralize a single word (in the form of a `Word` obj.) or pluralize all words in a `WordList`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'companies'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import\n",
    "from textblob import Word, WordList\n",
    "# create a Word object\n",
    "w = Word('company')\n",
    "# return the plural of a single word\n",
    "w.pluralize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['who', 'what', 'when', 'where', 'why'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Side note: we can also create WordList objects\n",
    "wl = WordList(['who','what','when','where','why'])\n",
    "wl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## singularization\n",
    "\n",
    "The opposite of pluralization: take a word (or words) in plural form and singularize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['agency', 'octopus', 'word'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wl = WordList(['agencies', 'octopi', 'words'])\n",
    "wl.singularize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Lemmatization takes a word that has been modified or morphed in some way using proper linguistic rules, and returns the stripped/unmodified version of it.\n",
    "\n",
    "The `lemmatize()` method has an optional parameter:\n",
    "* pos – Part of speech to filter upon. If None, defaults to _wordnet.NOUN.\n",
    "* options: \n",
    "    - `'n'` for noun, \n",
    "    - `'v'` for verb, \n",
    "    - `'a'` for adjective, \n",
    "    - `'r'` for adverb.\n",
    "\n",
    "Note: adverbs don't usually work with the standard `lemmatize` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sing'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = Word('singing')\n",
    "# for some words you have to pass the type\n",
    "# in this case we pass 'v' for verb (not to be confused with POS tag formats)\n",
    "w.lemmatize('v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# past participle verb\n",
    "w = Word('went')\n",
    "w.lemmatize('v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kindly'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it doesn't always work: try an adverb\n",
    "w = Word('kindly')\n",
    "w.lemmatize('r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Parsing & n-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Parsing gives us the syntactic structure of a string or sentence by appending each word with tags that indicate it's place in a hierarchy. See the tree in the PowerPoint slides for a visual example.\n",
    "\n",
    "Let's parse the sentence shown in the tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'John/NNP/B-NP/O loves/VBZ/B-VP/O Mary/NNP/B-NP/O'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return a string containing each word in the text along with its parts of speech hierarchy\n",
    "b = TextBlob('John loves Mary')\n",
    "b.parse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "`John/NNP/B-NP/O` gives the position in the hierarchy of the text for the word \"`John`\" in our sentence, working from the word to the top of the hierarchy.\n",
    "\n",
    "In this case (For the word `John`):\n",
    "* NNP indicates it is a \"noun, proper singular\"\n",
    "* the `B-` in `B-NP` indicates the word is: inside the chunk, preceding word is part of a different chunk\n",
    "* the `NP` in `B-NP` indicates it is part of a noun phrase\n",
    "* `O` is \"not part of chunk\", meaning we are at the end of this particular hierarchy (chunk).\n",
    "\n",
    "Details can be read on the page that gives detailed parts of speech (link posted under POS tagging).\n",
    "\n",
    "Parsing and syntactic structure is a complex subject, and is not covered in depth here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## n-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**n**-grams are groups of n successive words. Quite often n-grams are created by shifting one word at a time through a text, but there are cases where they skip k-words at a time.\n",
    "\n",
    "The usefulness of n-grams comes in with machine learning, where each n-gram is used as a feature for learning. These will be used more in the next workshop, but for now let's look at getting n-grams from a text using TextBlob:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "TextBlob has an `ngrams` method that will take an optional argument `n`, which is the size of n-grams to generate. Default is 3.\n",
    "\n",
    "The method returns a list of `WordList` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['VirginAmerica', 'status', 'match']),\n",
       " WordList(['status', 'match', 'program']),\n",
       " WordList(['match', 'program', 'I']),\n",
       " WordList(['program', 'I', 'applied']),\n",
       " WordList(['I', 'applied', 'and'])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return list of n-grams (default n=3)\n",
    "# get only first 5 n-grams\n",
    "blob.ngrams()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['VirginAmerica', 'status']),\n",
       " WordList(['status', 'match']),\n",
       " WordList(['match', 'program']),\n",
       " WordList(['program', 'I']),\n",
       " WordList(['I', 'applied'])]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get another set with n = 2\n",
    "blob.ngrams(n=2)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice Problems\n",
    "\n",
    "1. Create and parse blob (using index 25) and print the first 10 pieces on separate lines\n",
    "2. Singularize all words in blob\n",
    "3. Pluralize the words ['gallery', 'mouse', 'man']\n",
    "4. Lemmatize the words ['categories', 'mice', 'better', 'found']\n",
    "5. Print the first 5 unique POS tags in blob\n",
    "6. Given the n-grams in the last cell in the notebook, reconstruct the original sentence\n",
    "7. **Extra:** List all words in blob that are plural (with index of each word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For practice problem 6 in the second hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ngrams = [['The', 'quick', 'brown', 'fox'],\n",
    " ['quick', 'brown', 'fox', 'jumps'],\n",
    " ['brown', 'fox', 'jumps', 'over'],\n",
    " ['fox', 'jumps', 'over', 'the'],\n",
    " ['jumps', 'over', 'the', 'lazy'],\n",
    " ['over', 'the', 'lazy', 'dog'],\n",
    " ['the', 'lazy', 'dog', 'and'],\n",
    " ['lazy', 'dog', 'and', 'the'],\n",
    " ['dog', 'and', 'the', 'cow'],\n",
    " ['and', 'the', 'cow', 'jumped'],\n",
    " ['the', 'cow', 'jumped', 'over'],\n",
    " ['cow', 'jumped', 'over', 'the'],\n",
    " ['jumped', 'over', 'the', 'moon']]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
